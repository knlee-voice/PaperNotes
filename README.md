# Research Paper Notes 
## PAPER threads - (L)LM , GPT , NLP
* WALL-E 2.0: World Alignment by NeuroSymbolic Learning improves World Model-based LLM Agents - [arXiv/2504.15785](https://arxiv.org/pdf/2504.15785v1), [github](https://github.com/elated-sawyer/WALL-E)
* LLM Post-Training: A Deep Dive into Reasoning Large Language Models - [arXiv/2502.21321v2](https://arxiv.org/pdf/2502.21321v2), [github](https://github.com/mbzuai-oryx/Awesome-LLM-Post-training), [Fig.1](https://github.com/mbzuai-oryx/Awesome-LLM-Post-training/blob/main/Images/teasor.jpg)
* RewardBench: Evaluating Reward Models for Language Modeling - [arXiv/2403.13787](https://arxiv.org/pdf/2403.13787v1.pdf), [Leaderboard](https://huggingface.co/spaces/allenai/reward-bench), [Dataset](https://huggingface.co/datasets/allenai/reward-bench)
* Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge - [arXiv/2403.01432](https://arxiv.org/abs/2403.01432)
* LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models - [arXiv/2403.13372](https://arxiv.org/abs/2403.13372), [Demo Video](https://youtu.be/W29FgeZEpus?si=vhYd_dcGMt5lLTEo), [Code](https://github.com/hiyouga/LLaMA-Factory)
* Training language models to follow instructions with human feedback - [arXiv/2203.02155](https://arxiv.org/abs/2203.02155), [openAI blog](https://openai.com/blog/instruction-following/)
  - InstructGPT: minimize performance regressions on public NLP datasets by modifying our RLHF fine-tuning procedure.
  - Labelers significantly prefer InstructGPT outputs over outputs from GPT-3.
  - InstructGPT models show improvements in truthfulness over GPT-3 / 3 model sizes (1.3B, 6B, and 175B parameters)
* Model Stock: All we need is just a few fine-tuned models - [arXiv/2403.19522](https://arxiv.org/abs/2403.19522)
* BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation - [arXiv/2402.03216](https://arxiv.org/abs/2402.03216)
* TinyLlama: An Open-Source Small Language Model - [arXiv/2401.02385](https://arxiv.org/abs/2401.02385)
* GameGPT: Multi-agent Collaborative Framework for Game Development - [arXiv/2310.08067v1](https://arxiv.org/pdf/2310.08067v1)
* MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework - [arXiv/2308.00352v7](https://arxiv.org/pdf/2308.00352v7)
* ESRL: Efficient Sampling-based Reinforcement Learning for Sequence Generation - [arXiv/2308.02223](https://arxiv.org/abs/2308.02223), [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)
* Llama 2: Open Foundation and Fine-Tuned Chat Models - [arXiv/2307.09288](https://arxiv.org/abs/2307.09288)
* MegaBlocks: Efficient Sparse Training with Mixture-of-Experts - [arXiv/2211.15841](https://arxiv.org/abs/2211.15841), [Fig.MoE Layer](https://tenstorrent.com/wp-content/uploads/2023/11/MegaBlocks.png)
------
* Finetuned Language Models Are Zero-Shot Learners, Google Research - [arXiv/2109.01652](https://arxiv.org/pdf/2109.01652.pdf) 
  - Finetune on many tasks (“instruction-tuning”) / 175B GPT-3 zero-shot/few-shot 비교
* Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing - [arXiv/2107.13586](https://arxiv.org/pdf/2107.13586v1.pdf)(p.46)
  - #NLP #PLM / Fig: Typology of prompting methods
* Self-training Improves Pre-training for Few-shot Learning in Task-oriented Dialog Systems - [arXiv/2108.12589](https://arxiv.org/abs/2108.12589)
* AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing - [arXiv/2108.05542](https://arxiv.org/abs/2108.05542), #ASR #Benchmark
* A Survey on Automated Fact-Checking - [arXiv/2108.11896](https://arxiv.org/abs/2108.11896)
* LoRA: Low-Rank Adaptation of Large Language Models - [arXiv/2106.09685](https://arxiv.org/abs/2106.09685v2), [Code](https://github.com/microsoft/LoRA)
------
* Longformer: The Long-Document Transformer - [arXiv/2004.05150](https://arxiv.org/abs/2004.05150)
* ULMFiT: Universal Language Model Fine-tuning for Text Classification - [arXiv/1801.06146](https://arxiv.org/abs/1801.06146)
  
## PAPER threads - Agent 
* ADVANCES AND CHALLENGES IN FOUNDATION AGENTS: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems - [arXiv/2504.01990](https://arxiv.org/pdf/2504.01990v1), [github](https://github.com/FoundationAgents/awesome-foundation-agents). [Fig.1.2](https://github.com/FoundationAgents/awesome-foundation-agents/raw/main/assets/1-agent_framework.png)
* Zep: A Temporal Knowledge Graph Architecture for Agent Memory - [arXiv/2501.13956v1](https://arxiv.org/pdf/2501.13956v1), https://www.getzep.com/
* Eliza: A Web3 friendly AI Agent Operating System - [arXiv/2501.06781v2](https://arxiv.org/pdf/2501.06781v2)
* AgentLite: A Lightweight Library for Building and Advancing Task-Oriented LLM Agent System - [arXiv/2402.15538](https://arxiv.org/abs/2402.15538), [Fig.Illustration](https://d3i71xaburhd42.cloudfront.net/fc1dec23e44b7316cae4cda93ab0fdd1c56b2f28/9-Figure2-1.png)
* Adaptive In-conversation Team Building for Language Model Agents - [arXiv/2405.19425v2](https://arxiv.org/pdf/2405.19425v2)
* Generative Agents: Interactive Simulacra of Human Behavior - [arXiv/2304.03442v2](https://arxiv.org/pdf/2304.03442v2), [Fig.1](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*bLHYvHFoAIaYDY4hYScbcA.png)

## PAPER threads - RAG, Knowledge Base
* MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation - [arXiv/2501.06713v3](https://arxiv.org/pdf/2501.06713v3)
* Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG - [arXiv/2501.09136v2](https://arxiv.org/pdf/2501.09136v2)
* LIGHTRAG: SIMPLE AND FAST RETRIEVAL-AUGMENTED GENERATION - [arXiv/2410.05779v2](https://arxiv.org/pdf/2410.05779v2), [github](https://github.com/HKUDS/LightRAG)
* Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks -  [arXiv/2005.11401](https://arxiv.org/abs/2005.11401)
  
## PAPER threads - Foundation Models, Dataset 
* On the opportunity and risks of foundation models - [arXiv/2108.07258](https://arxiv.org/abs/2108.07258)(p.160)
* Datasets: A Community Library for Natural Language Processing - [arXiv/2109.02846](https://arxiv.org/pdf/2109.02846.pdf)
 
## PAPER threads - ASR, TTS, #Voice
* OpenVoice: Versatile Instant Voice Cloning - [arXiv/2312.01479](https://arxiv.org/abs/2312.01479), https://research.myshell.ai/open-voice
  - (Accurate Tone Color Cloning/Flexible Voice Style Control/Zero-shot Cross-lingual Voice Cloning)
* VALL-E X: Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling - [arXiv/2303.03926](https://arxiv.org/abs/2303.03926)
  - pre-train(60K hours) / [VALL-E_논문리뷰](https://kimjy99.github.io/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/vall-e/)
* ASR-GLUE: A New Multi-task Benchmark for ASR-Robust Natural Language Understanding - [arXiv/2108.13048](https://arxiv.org/abs/2108.13048), #Benchmark
* A Survey on Spoken Language Understanding: Recent Advances and New Frontiers - [arXiv/2103.03095](https://arxiv.org/abs/2103.03095)
* SpecAugment: A New Data Augmentation Method for Automatic Speech Recognition [[arXiv](https://arxiv.org/abs/1904.08779)], [[google AI blog](https://ai.googleblog.com/2019/04/specaugment-new-data-augmentation.html)] 
* Advances in All-Neural Speech Recognition [[arXiv/1609.05935](https://arxiv.org/abs/1609.05935)], [[note](https://github.com/knlee-voice/PaperNotes/blob/master/notes/aXv1609.05935.md)]
* Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence Labelling, 
* Personal Speech Recognition on Mobile Devices [[arXiv/1603.03185](https://arxiv.org/abs/1603.03185)], [[note](notes/aXv1603.03185.md)]
* Textless NLP: Generating expressive speech from raw audio - [facebook AI](https://ai.facebook.com/blog/textless-nlp-generating-expressive-speech-from-raw-audio)

## PAPER threads - YOLO, Multimodal 
* YOLOv11: An Overview of the Key Architectural Enhancements - [arXiv/2410.17725v1](https://arxiv.org/pdf/2410.17725v1)
  
---
# Links 
https://paperswithcode.com/
